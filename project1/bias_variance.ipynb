{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance tradeoff\n",
    "We do this to find the best order of complexity of our model. This is done based on the same method as used in the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scripts.proj1_helpers import *\n",
    "DATA_TRAIN_PATH = './data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX2, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)\n",
    "\n",
    "tX2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_data import clean_data\n",
    "tx = clean_data(tX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares.\"\"\"\n",
    "    a = tx.T.dot(tx)\n",
    "    b = tx.T.dot(y)\n",
    "    return np.linalg.solve(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variance_decomposition_visualization(degrees, rmse_tr, rmse_te):\n",
    "    \"\"\"visualize the bias variance decomposition.\"\"\"\n",
    "    f = plt.figure(figsize = (15,10))\n",
    "    rmse_tr_mean = np.expand_dims(np.mean(rmse_tr, axis=0), axis=0)\n",
    "    rmse_te_mean = np.expand_dims(np.mean(rmse_te, axis=0), axis=0)\n",
    "    \"\"\"\n",
    "    plt.plot(\n",
    "        degrees,\n",
    "        rmse_tr.T,\n",
    "        'b',\n",
    "        linestyle=\"-\",\n",
    "        color=([0.7, 0.7, 1]),\n",
    "        label='train',\n",
    "        linewidth=0.3)\n",
    "    #plt.plot(\n",
    "        degrees,\n",
    "        rmse_te.T,\n",
    "        'r',\n",
    "        linestyle=\"-\",\n",
    "        color=[1, 0.7, 0.7],\n",
    "        label='test',\n",
    "        linewidth=0.3)\n",
    "    plt.plot(\n",
    "        degrees,\n",
    "        rmse_tr_mean.T,\n",
    "        'b',\n",
    "        linestyle=\"-\",\n",
    "        label='train',\n",
    "        linewidth=3) \"\"\"\n",
    "    plt.plot(\n",
    "        degrees,\n",
    "        rmse_te_mean.T,\n",
    "        'r',\n",
    "        linestyle=\"-\",\n",
    "        label='test',\n",
    "        linewidth=3)\n",
    "    plt.xlabel(\"degree\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(\"Bias-Variance Decomposition\")\n",
    "    plt.savefig(\"bias_variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.proj1_helpers import *\n",
    "\n",
    "def bias_variance(y, x):\n",
    "    \n",
    "    seeds = range(10)\n",
    "    ratio_train = 0.01\n",
    "    degrees = range(15)\n",
    "    # define list to store the variable\n",
    "    rmse_tr = np.empty((len(seeds), len(degrees)))\n",
    "    rmse_te = np.empty((len(seeds), len(degrees)))\n",
    "    \n",
    "    for index_seed, seed in enumerate(seeds):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Split data\n",
    "        y_tr, x_tr, y_te, x_te = split_data(y, x, ratio_train, seed)\n",
    "        \n",
    "        for degree in degrees:\n",
    "            tx_tr = build_poly(x_tr, degree)\n",
    "            tx_te = build_poly(x_te, degree)\n",
    "\n",
    "            w = least_squares(y_tr, tx_tr)\n",
    "            \n",
    "            loss_tr = compute_mse(y_tr, tx_tr, w)\n",
    "            loss_te = compute_mse(y_te, tx_te, w)\n",
    "            \n",
    "            rmse_tr[index_seed, degree-1] = np.sqrt(2*loss_tr)\n",
    "            rmse_te[index_seed, degree-1] = np.sqrt(2*loss_te)\n",
    "\n",
    "    return degrees, rmse_tr, rmse_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees, rmse_tr, rmse_te = bias_variance(y, tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_tr[-1], rmse_te[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_variance_decomposition_visualization(degrees, rmse_tr, rmse_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
